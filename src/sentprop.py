import numpy as np
from scipy.sparse import csr_matrix, spdiags

from tqdm import tqdm, trange

def sparse_matmul(a, b, nn, desc=""):
    """
    Do smart multiplication on two dense arrays to get a sparse representation,
    keeping only the top nn values in each row.  The two matrices must already be
    of valid multiplying shape--this function does not transformations on them.
    """
    indptr = np.arange(a.shape[0] + 1, dtype=np.int64) * nn
    indices = np.empty(a.shape[0] * nn, dtype=np.int64)
    data = np.empty_like(indices, dtype=np.float32)

    for i in trange(a.shape[0], mininterval=5, position=1, desc=desc):
        currow = a[i].dot(b)
        argsorted = np.argsort(currow)[-nn:]
        data[nn*i:nn*(i + 1)] = currow[argsorted]
        indices[nn*i:nn*(i + 1)] = argsorted

    ret_matrix = csr_matrix((data, indices, indptr), shape=(a.shape[0], a.shape[0]))
    return ret_matrix


def generate_transition_matrix(vecs, beta, nn, desc=""):
    """
    Generate the transition matrix from a given set of vectors.

    :param vecs: np.ndarray, shape (n_vocab, n_embedding_dims)
        numpy array containing one word vector per row
    :param beta: float
        beta parameter in socialsent algorithm.  High beta --> similar
        labels for neighbors; low beta --> more correct labels on seed words
    :param nn: int
        Number of neighbors to consider when performing the random walk with
        teleportation.
    :return: dict, {vocab_item:sentiment_score}
    """
    E = vecs.astype(np.float32)
    E = np.nan_to_num(E / np.linalg.norm(E, axis=1, keepdims=True))
    print("Matrix multiplication and arccos.  This will take some time.")
    sims = sparse_matmul(E, E.T, nn, desc=desc)
    del E
    sims.data = np.arccos(-np.clip(sims.data, -1, 1))
    print("...done")
    # np.sum(csr_matrix) --> numpy matrix.  Cast to array to get 2d ndarray,
    # pull first item out to get a simple 1d array.  Then clip it
    # at 0, following the SentProp CODE--this is not mentioned in the
    # paper--and take the square root, then create a sparse diagonal matrix.
    D = np.array(np.sum(sims, axis=0))[0]
    D = np.array([1 / i if i > 0 else 0 for i in D])
    D = spdiags(
        np.sqrt(D),
        0, sims.shape[0], sims.shape[0]
    )
    print("Generating transition matrix...")
    T = beta * (D.dot(sims).dot(D))
    return T

def propagate_scores(id2word, vecs, T, seeds, tol, beta, maxiter, print_name):
    """
    Given a transition matrix and vocab, run the sentprop algorithm to
    propagate the labels as per a random walk.
    :param id2word: gensim Dicionary object trained on the corpus
    :param vecs: array of word-vectors, such that the ith row
        is the token id2word[i].
    :param T: csr_matrix; the transition matrix, generated by generate_transition_matrix().
    :param seeds: the seed words for this propagation.
    :param tol: the tolerance for convergence.
    :param beta: the beta parameter in the sentprop algorithm.
    :param maxiter: maximum number of iterations after which to force a stop,
        regardless of how close to convergence the program is.
    """
    s = np.array([
        1 / len(seeds) if id2word[i] in seeds else 0
        for i in sorted(id2word.keys())
    ], dtype=np.float32)
    p = np.ones(vecs.shape[0], dtype=np.float32) / vecs.shape[1]

    delta = tol + 1
    counter = 0
    while delta > tol and counter < maxiter:
        p_old = np.copy(p)
        p = T.dot(p) + (1 - beta) * s
        delta = np.sum(np.abs(p - p_old))
        counter += 1

    if counter == maxiter:
        print(f"{print_name}: reached {max_iter} iterations, terminating.")
    else:
        print(f"{print_name}: converged after {counter} iterations.")

    return p

def main(id2word, vecs, pos_seeds, neg_seeds, tol, beta, nn, maxiter, print_name):
    T = generate_transition_matrix(vecs, beta, nn, desc=print_name)
    p_pos = propagate_scores(id2word, vecs, T, pos_seeds, tol, beta, maxiter, print_name)
    p_neg = propagate_scores(id2word, vecs, T, neg_seeds, tol, beta, maxiter, print_name)
    p = p_pos / (p_pos + p_neg)
    p = (p - p.mean()) / p.std()
    return {id2word[i]:p[i] for i in range(p.shape[0])}
